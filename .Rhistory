strat<-epi.2by2(dat=tab2, method="case.control")
tab2 <- table(bronchit$hilevel[bronchit$agegp>=1],bronchit$bronchit[bronchit$agegp>=1],bronchit$agegp[bronchit$agegp>=1])
strat<-epi.2by2(dat=tab2, method="case.control")
knitr::opts_chunk$set(echo = TRUE)
bronchit <- read.dta(file.choose())
library(foreign)
bronchit <- read.dta(file.choose())
cont_table <- table(bronchit = bronchit$bronchit,
hilevel = bronchit$hilevel,
agegp = bronchit$agegp)
library(epiR)
#tab2 <- table(bronchit$hilevel,bronchit$bronchit,bronchit$agegp)
strat<-epi.2by2(dat=cont_table , method="case.control")
strat$massoc.detail$OR.strata.wald
epi.2by2(dat=cont_table , method="case.control")
load("~/Downloads/car_environmentLast.RData")
knitr::opts_chunk$set(echo = TRUE)
step <- stepAIC(car_model_box, direction="both")
#guardiamo i valori dell'AIC per vedere qual Ã¨ il miglior modello
library(MASS)
step <- stepAIC(car_model_box, direction="both")
ls(step)
step
step$anova
step <- stepAIC(car_model_box, direction="both")
View(dataCar)
names(dataCar)
names(dataCar)
dataCar <- dataCar[,-c(2,5,7,13)]
model_box_selection <- car_model_box<-lm((price^teta)/teta~.,dataCar)
names(dataCar)
dataCar <- dataCar[,-c(2,5,7,13)]
model_box_selection <- lm((price^teta)/teta~.,dataCar)
summary(model_box_selection)
plot(model_box_selection)
plot(car_model)
plot(car_model_box)
plot(model_box_selection)
summary(model_box_selection)
plot(car_model)
plot(car_model_box)
plot(model_box_selection)
leverageP<-hatvalues(model_box_selection)
summary(leverageP)
leverageP<-hatvalues(model_box_selection)
summary(leverageP)
#soglia
p<-length(model_box_selection$coefficients)+1
n<-length(model_box_selection$residuals)
leverage_treshold<-2*p/n
plot(leverageP,
main="Punti di leva piano Processo chimico",
ylab="Punti di leva hii",
xlab="indice unit?",
col ="blue")
abline(h=leverage_treshold,
col="red")
require(faraway)
halfnorm(leverageP,
ylab="coeff. di leva normalizzati")
install.packages('faraway')
plot(leverageP,
main="Punti di leva piano Processo chimico",
ylab="Punti di leva hii",
xlab="indice unit?",
col ="blue")
abline(h=leverage_treshold,
col="red")
require(faraway)
halfnorm(leverageP,
ylab="coeff. di leva normalizzati")
cooksd <- cooks.distance(Robust_ModSel)
cooksd <- cooks.distance(model_box_selection)
load("~/Downloads/car_environmentLast.RData")
names(dataCar)
dataCar <- dataCar[,-c(2,5,7,13)]
model_box_selection <- lm((price^teta)/teta~.,dataCar)
summary(model_box_selection)
plot(car_model)
plot(car_model_box)
plot(model_box_selection)
plot(leverageP,
main="Punti di leva piano Processo chimico",
ylab="Punti di leva hii",
xlab="indice unit?",
col ="blue")
leverageP<-hatvalues(model_box_selection)
summary(leverageP)
#soglia
p<-length(model_box_selection$coefficients)+1
n<-length(model_box_selection$residuals)
leverage_treshold<-2*p/n
plot(leverageP,
main="Punti di leva piano Processo chimico",
ylab="Punti di leva hii",
xlab="indice unit?",
col ="blue")
abline(h=leverage_treshold,
col="red")
require(faraway)
halfnorm(leverageP,
ylab="coeff. di leva normalizzati")
cooksd <- cooks.distance(model_box_selection)
cook_treshold <- 4/(length(model_box_selection$residuals)-length(model_box_selection$coefficients)-1)
plot(model_box_selection, which=4, cook.levels=cook_treshold)
abline(h=cook_treshold, col="red")
halfnorm(cooksd)
model_box_selection$residuals[44]
mean(dataCar$horsepower)
dataCar[44,]
model_box_selection$residuals[129]
cook_treshold <- 4/(length(model_box_selection$residuals)-length(model_box_selection$coefficients)-1)
plot(model_box_selection, which=4, cook.levels=cook_treshold)
abline(h=cook_treshold, col="red")
halfnorm(cooksd)
model_box_selection$residuals[129]
mean(dataCar$horsepower)
dataCar[129,]
cook_treshold <- 4/(length(model_box_selection$residuals)-length(model_box_selection$coefficients)-1)
plot(model_box_selection, which=4, cook.levels=cook_treshold)
abline(h=cook_treshold, col="red")
halfnorm(cooksd)
model_box_selection$residuals[129]
mean(dataCar$horsepower)
dataCar[129,]
desc(dataCar)
cook_treshold <- 4/(length(model_box_selection$residuals)-length(model_box_selection$coefficients)-1)
plot(model_box_selection, which=4, cook.levels=cook_treshold)
abline(h=cook_treshold, col="red")
halfnorm(cooksd)
model_box_selection$residuals[129]
mean(dataCar$horsepower)
dataCar[129,]
str(dataCar)
cook_treshold <- 4/(length(model_box_selection$residuals)-length(model_box_selection$coefficients)-1)
plot(model_box_selection, which=4, cook.levels=cook_treshold)
abline(h=cook_treshold, col="red")
halfnorm(cooksd)
model_box_selection$residuals[129]
mean(dataCar$horsepower)
dataCar[129,]
str(dataCar)
summary(dataCar)
cook_treshold <- 4/(length(model_box_selection$residuals)-length(model_box_selection$coefficients)-1)
plot(model_box_selection, which=4, cook.levels=cook_treshold)
abline(h=cook_treshold, col="red")
halfnorm(cooksd)
model_box_selection$residuals[129]
mean(dataCar$horsepower)
dataCar[129,]
summary(dataCar)
cook_treshold <- 4/(length(model_box_selection$residuals)-length(model_box_selection$coefficients)-1)
plot(model_box_selection, which=4, cook.levels=cook_treshold)
abline(h=cook_treshold, col="red")
halfnorm(cooksd)
model_box_selection$residuals[3]
mean(dataCar$horsepower)
dataCar[3,]
summary(dataCar)
library(car)
influencePlot(Robust_ModSel,  main="Influence Plot" )
install.packages('car')
install.packages("car")
library(car)
influencePlot(Robust_ModSel,  main="Influence Plot" )
library(car)
influencePlot(model_box_selection,  main="Influence Plot" )
Influenti <- as.numeric(names(cooksd)[(cooksd < cook_treshold)])
dataCarNoInflu=data.frame(dataCar[cooksd <  cook_treshold, ])
model_No_Influ <- lm(((price^teta)/teta)~., data=dataCarNoInflu)
summary(model_No_Influ)$adj.r.squared
par(mfrow=c(2,2))
plot(model_No_Influ)
par(mfrow=c(1,1))
#Togliamo ora i punti Maggiormente influenti ed i punti di leva
dataCar=data.frame(dataCar[(cooksd <  cook_treshold) || (leverageP < leverage_treshold), ])
#Togliamo ora i punti Maggiormente influenti ed i punti di leva
dataCar=data.frame(dataCar[(cooksd <  cook_treshold) || (leverageP < leverage_treshold), ])
#Ristimiamo ora il modello privo di valori Influenti e di Leverage Point
model_No_Influ <- lm(((price^teta)/teta)~., data=dataCar)
summary(RobustFree)
#Togliamo ora i punti Maggiormente influenti ed i punti di leva
dataCar=data.frame(dataCar[(cooksd <  cook_treshold) || (leverageP < leverage_treshold), ])
#Ristimiamo ora il modello privo di valori Influenti e di Leverage Point
model_No_Influ <- lm(((price^teta)/teta)~., data=dataCar)
summary(model_No_Influ)
par(mfrow=c(2,2))
plot(model_No_Influ)
par(mfrow=c(1,1))
plot(model_No_Influ)
plot(model_box_selection)
#Togliamo ora i punti Maggiormente influenti ed i punti di leva
dataCar=data.frame(dataCar[(cooksd <  cook_treshold) || (leverageP < leverage_treshold), ])
#Ristimiamo ora il modello privo di valori Influenti e di Leverage Point
model_No_Influ <- lm(((price^teta)/teta)~., data=dataCar)
summary(model_No_Influ)
par(mfrow=c(2,2))
plot(model_box_selection)
plot(model_No_Influ)
par(mfrow=c(1,1))
plot(model_box_selection)
plot(model_No_Influ)
#Togliamo ora i punti Maggiormente influenti ed i punti di leva
dataCarNoInfluNoLev=data.frame(dataCar[(cooksd <  cook_treshold) || (leverageP < leverage_treshold), ])
#Ristimiamo ora il modello privo di valori Influenti e di Leverage Point
model_No_Influ <- lm(((price^teta)/teta)~., data=dataCarNoInfluNoLev)
summary(model_No_Influ)
par(mfrow=c(2,2))
plot(model_box_selection)
plot(model_No_Influ)
par(mfrow=c(1,1))
load("~/Downloads/car_environmentLast.RData")
names(dataCar)
dataCar <- dataCar[,-c(2,5,7,13)]
model_box_selection <- lm((price^teta)/teta~.,dataCar)
leverageP<-hatvalues(model_box_selection)
summary(leverageP)
#soglia
p<-length(model_box_selection$coefficients)+1
n<-length(model_box_selection$residuals)
leverage_treshold<-2*p/n
plot(leverageP,
main="Punti di leva piano Processo chimico",
ylab="Punti di leva hii",
xlab="indice unit?",
col ="blue")
abline(h=leverage_treshold,
col="red")
require(faraway)
halfnorm(leverageP,
ylab="coeff. di leva normalizzati")
cooksd <- cooks.distance(model_box_selection)
cook_treshold <- 4/(length(model_box_selection$residuals)-length(model_box_selection$coefficients)-1)
plot(model_box_selection, which=4, cook.levels=cook_treshold)
abline(h=cook_treshold, col="red")
halfnorm(cooksd)
model_box_selection$residuals[3]
mean(dataCar$horsepower)
dataCar[3,]
summary(dataCar)
library(car)
influencePlot(model_box_selection,  main="Influence Plot" )
Influenti <- as.numeric(names(cooksd)[(cooksd < cook_treshold)])
dataCarNoInflu=data.frame(dataCar[cooksd <  cook_treshold, ])
model_No_Influ <- lm(((price^teta)/teta)~., data=dataCarNoInflu)
summary(model_No_Influ)$adj.r.squared
par(mfrow=c(2,2))
plot(model_No_Influ)
par(mfrow=c(1,1))
#Togliamo ora i punti Maggiormente influenti ed i punti di leva
dataCarNoInfluNoLev=data.frame(dataCar[(cooksd <  cook_treshold) || (leverageP < leverage_treshold), ])
#Ristimiamo ora il modello privo di valori Influenti e di Leverage Point
model_No_Influ <- lm(((price^teta)/teta)~., data=dataCarNoInfluNoLev)
summary(model_No_Influ)
par(mfrow=c(2,2))
plot(model_box_selection)
plot(model_No_Influ)
par(mfrow=c(1,1))
#Togliamo ora i punti Maggiormente influenti ed i punti di leva
dataCarNoInfluNoLev=data.frame(dataCarNoInflu[leverageP < leverage_treshold, ])
#Ristimiamo ora il modello privo di valori Influenti e di Leverage Point
model_No_Influ <- lm(((price^teta)/teta)~., data=dataCarNoInfluNoLev)
summary(model_No_Influ)
plot(model_box_selection)
plot(model_box_selection)
plot(model_No_Influ)
library(gvlma)
install.packages('gvlma')
library(gvlma)
gvlma(model_No_Influ)
summary(model_No_Influ)
summary(car_model)
summary(car_model_box)
summary(model_box_selection)
summary(model_No_Influ)
drop1(model_No_Influ, test="F")
names(dataCarNoInfluNoLev)
drop1(model_No_Influ, test="F")
drop1(model_No_Influ, test="F")
names(dataCarNoInfluNoLev)
#dataCarNoInfluNoLev<-dataCarNoInfluNoLev[,-c()]
drop1(model_No_Influ, test="F")
names(dataCarNoInfluNoLev)
dataCarNoInfluNoLev<-dataCarNoInfluNoLev[,-c(6,7,11)]
RobustMod<-lm(((price^teta)/teta)~., data=dataCarNoInfluNoLev)
summary(RobustMod)
drop1(model_No_Influ, test="F")
names(dataCarNoInfluNoLev)
#dataCarNoInfluNoLev<-dataCarNoInfluNoLev[,-c(6,7,11)]
RobustMod<-lm(((price^teta)/teta)~., data=dataCarNoInfluNoLev)
summary(RobustMod)
plot(RobustMod)
summary(RobustMod)
plot(car_model)
plot(RobustMod)
save.image("~/Downloads/final_car_environment.RData")
library(keras)
library(tidyverse)
install.packages('tidyverse')
install.packages("tidyverse")
library(tidyverse)
library(keras)
library(tidyverse)
library(keras)
library(tidyverse)
load("~/Documents/GitHub/Tetouan-Power-Consumption-Forecasting/env.RData")
setwd("/Users/giannellig/Documents/GitHub/Tetouan-Power-Consumption-Forecasting")
num_lags <- 24*7
# aggregate data by hour
data_xts_agg <- period.apply(data_xts, endpoints(data_xts, "hours"), mean)
num_lags <- 24*7
# aggregate data by hour
data_xts_agg <- period.apply(data_xts, endpoints(data_xts, "hours"), mean)
set.seed(2207)
Sys.setenv(TZ='GMT') # imposto la time zone
packages <- c("forecast", "KFAS", "xts", "fastDummies", "tsfknn", "MASS", "tidyr", "ggplot2", "lubridate", "randomForest", "ranger", "tibble", "keras") # librerie
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
num_lags <- 24*7
# aggregate data by hour
data_xts_agg <- period.apply(data_xts, endpoints(data_xts, "hours"), mean)
index(data_xts_agg) <- index(data_xts_agg)-600*2
wday <- wday(time(data_xts_agg), week_start = getOption("lubridate.week.start", 1)) # day of the week
lags <- embed(data_xts_agg, (num_lags+1))[,-1]
y_ml <- data_xts_agg[-(1:num_lags)]
x_ml <- cbind(wday[-(1:num_lags)], lags)
# split in train and val
y_ml_train <- y_ml[1:as.integer(val_index/6-num_lags)]
x_ml_train <- x_ml[1:as.integer(val_index/6-num_lags),]
y_ml_val <- y_ml[as.integer(val_index/6-(num_lags-1)):nrow(y_ml)]
x_ml_val <- x_ml[as.integer(val_index/6-(num_lags-1)):nrow(y_ml),]
# training
ml_mod3 <- randomForest(x_ml_train, y_ml_train,
ntree=400)
# predictions
ml_pred3 <- c()
elem <- x_ml_val[1,] # first elem of val
for (i in 1:nrow(y_ml_val)){
pr <- predict(ml_mod3, newdata = elem)
elem <- elem[-length(elem)] # remove last elem
elem <- append(elem, pr, after=1) # add new elem
ml_pred3 <- append(ml_pred3, pr)
}
ml_pred3 <- as.xts(ml_pred3, order.by = index(y_ml_val))
# imputation
temp <- xts(rep(as.numeric(NA), length(val)), index(val))
ml_pred3 <- merge(temp, ml_pred3)$ml_pred3
ml_pred3 <- na.approx(ml_pred3, na.rm = FALSE)
ml_pred3 <- na.locf(ml_pred3, na.rm = FALSE)
ml_pred3 <- na.locf(ml_pred3, fromLast = TRUE)
names(ml_pred3) <- "V1"
plot_pred(ml_pred3)
stats_results[nrow(stats_results) + 1,] <- c("ml_mod3", stats(val, ml_pred3))
df_plot_pred <- merge.xts(ground_truth = data_xts[(val_index-144*4):nrow(data_xts),], pred = ml_pred3)
df_plot_pred <- data.frame(df_plot_pred, date=index(df_plot_pred))
p <- ggplot() +
geom_line(data = df_plot_pred, aes(x = date, y = ground_truth)) +
geom_line(data = df_plot_pred, aes(x = date, y = pred), color = "yellow") +
geom_vline(xintercept=as.numeric(df_plot_pred$date[144*4]), linetype=2) +
xlab('Date') +
ylab('Power')
p
p
plot_pred(ml_pred3)
stats_results[nrow(stats_results) + 1,] <- c("ml_mod3", stats(val, ml_pred3))
df_plot_pred <- merge.xts(ground_truth = data_xts[(val_index-144*4):nrow(data_xts),], pred = ml_pred3)
df_plot_pred <- data.frame(df_plot_pred, date=index(df_plot_pred))
p <- ggplot() +
geom_line(data = df_plot_pred, aes(x = date, y = ground_truth)) +
geom_line(data = df_plot_pred, aes(x = date, y = pred), color = "yellow") +
geom_vline(xintercept=as.numeric(df_plot_pred$date[144*4]), linetype=2) +
xlab('Date') +
ylab('Power')
p
View(ml_pred3)
ml_pred3
plot_pred(ml_pred3)
stats_results[nrow(stats_results) + 1,] <- c("ml_mod3", stats(val, ml_pred3))
?knn_forecasting
ml_mod1 <- function(train){
knn_forecasting(ts(train),
h = 144*npred,
lags = 1:(144*7),
msas = "MIMO",
transform = "multiplicative")}
ml_pred1 <- ml_mod1(train)
ml_pred1 <- xts(ml_pred1$prediction, index(val))
plot_pred(ml_pred1)
stats_results[nrow(stats_results) + 1,] <- c("ml_mod1", stats(val, ml_pred1))
df_plot_pred <- merge.xts(ground_truth = data_xts[(val_index-144*4):nrow(data_xts),], pred = ml_pred1)
df_plot_pred <- data.frame(df_plot_pred, date=index(df_plot_pred))
p <- ggplot() +
geom_line(data = df_plot_pred, aes(x = date, y = ground_truth)) +
geom_line(data = df_plot_pred, aes(x = date, y = pred), color = "yellow") +
geom_vline(xintercept=as.numeric(df_plot_pred$date[144*4]), linetype=2) +
xlab('Date') +
ylab('Power')
p
ggsave('plots/ml_pred.jpg', p, height = 2 , width = 6)
plot_pred(ml_pred1)
stats_results[nrow(stats_results) + 1,] <- c("ml_mod1", stats(val, ml_pred1))
df_plot_pred <- merge.xts(ground_truth = data_xts[(val_index-144*4):nrow(data_xts),], pred = ml_pred1)
df_plot_pred <- data.frame(df_plot_pred, date=index(df_plot_pred))
p <- ggplot() +
geom_line(data = df_plot_pred, aes(x = date, y = ground_truth)) +
geom_line(data = df_plot_pred, aes(x = date, y = pred), color = "purple") +
geom_vline(xintercept=as.numeric(df_plot_pred$date[144*4]), linetype=2) +
xlab('Date') +
ylab('Power')
p
ggsave('plots/ml_pred.jpg', p, height = 2 , width = 6)
load("~/Documents/GitHub/Tetouan-Power-Consumption-Forecasting/env.RData")
ml_mod1 <- function(train){
knn_forecasting(ts(train),
h = 144*npred,
lags = 1:(144*7),
msas = "MIMO",
transform = "multiplicative")}
ml_pred1 <- ml_mod1(train)
ml_pred1 <- xts(ml_pred1$prediction, index(val))
plot_pred(ml_pred1)
stats_results[nrow(stats_results) + 1,] <- c("ml_mod1", stats(val, ml_pred1))
df_plot_pred <- merge.xts(ground_truth = data_xts[(val_index-144*4):nrow(data_xts),], pred = ml_pred1)
df_plot_pred <- data.frame(df_plot_pred, date=index(df_plot_pred))
p <- ggplot() +
geom_line(data = df_plot_pred, aes(x = date, y = ground_truth)) +
geom_line(data = df_plot_pred, aes(x = date, y = pred), color = "purple") +
geom_vline(xintercept=as.numeric(df_plot_pred$date[144*4]), linetype=2) +
xlab('Date') +
ylab('Power')
p
ggsave('plots/ml_pred.jpg', p, height = 2 , width = 6)
train_gen_nov <- data_xts_complete[1:(val_index+144*npred-1),]
# arima train
train_gen_nov_dummy <- fastDummies::dummy_cols(format(index(train_gen_nov), "%u"), remove_selected_columns = TRUE, remove_first_dummy = TRUE)
rownames(train_gen_nov_dummy) <- index(train_gen_nov)
colnames(train_gen_nov_dummy) <- c("mart", "merc", "giov", "ven", "sab", "dom")
train_gen_nov_dummy <- as.matrix(train_gen_nov_dummy)
test_gen_nov_dummy <- fastDummies::dummy_cols(format(index(test), "%u"), remove_selected_columns = TRUE, remove_first_dummy = TRUE)
rownames(test_gen_nov_dummy) <- index(test)
colnames(test_gen_nov_dummy) <- c("mart", "merc", "giov", "ven", "sab", "dom")
test_gen_nov_dummy <- as.matrix(test_gen_nov_dummy)
# ucm train
tseq <- seq(from = index(train_gen_nov[nrow(train_gen_nov),])+600, length.out = 144*npred, by = 600)
train_gen_nov_ucm <- c(train_gen_nov, xts(rep(as.numeric(NA), length(tseq)), tseq)) # aggiungo NA a train
stats_results
View(stats_results)
stats_results<-[-c(1),]
stats_results<-stats_results[-c(1),]
stats_results
dic_arima_train <- arima_mod4(train_gen_nov, train_gen_nov_dummy)
dic_arima_pred <- forecast(dic_arima_train, 144*npred, xreg=test_gen_nov_dummy)
dic_arima_pred <- xts(dic_arima_pred$mean, index(test))
dic_arima_pred
dic_ucm <- ucm_mod2(train_gen_nov_ucm) # modello 1
dic_ucm_pred <- dic_ucm[(nrow(dic_ucm)-144*npred+1):nrow(dic_ucm)]
dic_arima_train
dic_ml <- ml_mod1(train_gen_nov)$prediction # modello 1
dic_ml_pred <- xts(dic_ml, index(test))
dic_ml
results <- data.frame(date = index(test),
ARIMA = dic_arima_pred,
UCM = dic_ucm_pred,
ML = dic_ml_pred)
sum(results$ARIMA)
sum(results$UCM)
sum(results$ML)
df_plot_pred <- merge.xts(Actual = data_xts_complete[(test_index-144*4):nrow(data_xts_complete),], ARIMA = dic_arima_pred)
df_plot_pred <- merge.xts(df_plot_pred, UCM = dic_ucm_pred)
df_plot_pred <- merge.xts(df_plot_pred, SVM = dic_ml_pred)
df_plot_pred <- data.frame(df_plot_pred, date=index(df_plot_pred))
df <- gather(df_plot_pred, Model, Values, Actual:SVM)
p <- ggplot(data = df, aes(x=date, y=Values)) +
geom_line(aes(color = Model), size = 0.5) +
labs(y = "Power", x = '') +
scale_color_manual(values=c("black", "#F8766D", "#00BA38", "#619CFF")) +
geom_vline(xintercept=as.numeric(df_plot_pred$date[144*4]), linetype=2)
p
ggsave('plots/december_forecasts_comparison.jpg', p, height = 3 , width = 3 * 4)
df_plot_pred <- merge.xts(Actual = data_xts_complete[(test_index-144*4):nrow(data_xts_complete),], ARIMA = dic_arima_pred)
df_plot_pred <- merge.xts(df_plot_pred, UCM = dic_ucm_pred)
df_plot_pred <- merge.xts(df_plot_pred, SVM = dic_ml_pred)
df_plot_pred <- data.frame(df_plot_pred, date=index(df_plot_pred))
df <- gather(df_plot_pred, Model, Values, Actual:SVM)
p <- ggplot(data = df, aes(x=date, y=Values)) +
geom_line(aes(color = Model), size = 0.5) +
labs(y = "Power", x = '') +
scale_color_manual(values=c("black", "#F8766D", "#00BA38", "purple")) +
geom_vline(xintercept=as.numeric(df_plot_pred$date[144*4]), linetype=2)
p
ggsave('plots/december_forecasts_comparison.jpg', p, height = 3 , width = 3 * 4)
df_plot_pred <- merge.xts(Actual = data_xts_complete[(test_index-144*4):nrow(data_xts_complete),], ARIMA = dic_arima_pred)
df_plot_pred <- merge.xts(df_plot_pred, UCM = dic_ucm_pred)
df_plot_pred <- merge.xts(df_plot_pred, SVM = dic_ml_pred)
df_plot_pred <- data.frame(df_plot_pred, date=index(df_plot_pred))
df <- gather(df_plot_pred, Model, Values, Actual:SVM)
p <- ggplot(data = df, aes(x=date, y=Values)) +
geom_line(aes(color = Model), size = 0.5) +
labs(y = "Power", x = '') +
scale_color_manual(values=c("black", "#F8766D", "purple", "#619CFF")) +
geom_vline(xintercept=as.numeric(df_plot_pred$date[144*4]), linetype=2)
p
ggsave('plots/december_forecasts_comparison.jpg', p, height = 3 , width = 3 * 4)
stats_results
write.csv(results, "846586_16062023.csv", row.names=FALSE) # cambiare data
write.csv(results, "846586_16062023.csv", row.names=FALSE) # cambiare data
save.image("~/Documents/GitHub/Tetouan-Power-Consumption-Forecasting/env.RData")
save.image("~/Documents/GitHub/Tetouan-Power-Consumption-Forecasting/env.RData")
